{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems\n",
    "    1. Fix the download pdf from link function\n",
    "        1.1 file stuck at download\n",
    "        1.2 broken file download\n",
    "    2. Turn it int OOP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from googlesearch import search\n",
    "import webbrowser\n",
    "import re\n",
    "import urllib.request\n",
    "import requests\n",
    "import bs4\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fake_useragent import UserAgent\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_comp_list(path = \"Top 500 companies.txt\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        comp_list = f.readlines()\n",
    "    return comp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching PDF with no block(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_results(keyword, n_results=10):\n",
    "    query = keyword\n",
    "    query = urllib.parse.quote_plus(query) # Format into URL encoding\n",
    "    number_result = n_results\n",
    "    ua = UserAgent()\n",
    "    google_url = f\"https://www.google.com/search?q= {query} &num= + {number_result}\"\n",
    "    response = requests.get(google_url, {\"User-Agent\": ua.random})\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    links = get_links(soup)\n",
    "    titles = get_title_list(soup)\n",
    "    desc_list = get_desc(soup)\n",
    "    lst = []\n",
    "    for (l,t,d) in zip(links,titles,desc_list):\n",
    "        lst.append({\"title\" : t, \"link\" : l, \"desc\" : d})\n",
    "    return lst[:number_result]\n",
    "\n",
    "def get_links(soup):\n",
    "    result = soup.find_all('div', attrs = {'class': 'ZINbbc'})\n",
    "    pattern = '\\/url\\?q\\=(.*)\\&sa'\n",
    "    results = []\n",
    "    for i in result:\n",
    "        if \"url\" in str(i):\n",
    "            text = str(i.find('a', href = True)['href'])\n",
    "            results.append(re.search(pattern,text))\n",
    "    #group(1) returns the text of the match object\n",
    "    links=[i.group(1) for i in results if i != None]\n",
    "    return links\n",
    "\n",
    "def get_title_list(soup):\n",
    "    result = soup.find_all('h3', attrs = {'class': 'zBAuLc'})\n",
    "    titles = [i.text for i in result]\n",
    "    return titles\n",
    "\n",
    "def get_desc(soup):\n",
    "    result = soup.findAll(True, {'class':\"kCrYT\"})\n",
    "    desc_list = []\n",
    "    for i,r in enumerate(result):\n",
    "        if i % 2 != 0:\n",
    "            desc_list.append(r.text)     \n",
    "    return desc_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_get_pdf(n = None,year = None, c=None):\n",
    "    if c == None:\n",
    "        c = int(input(\"Enter\\n1. Normal Downlaod\\n2. Redownload \\n\"))\n",
    "    if c == 1:\n",
    "        comp_list = get_comp_list()\n",
    "        if year == None:\n",
    "            year = int(input(\"Enter year : \"))\n",
    "        if n == None:\n",
    "            n = int(input(\"How many companies would you like to search? : \"))\n",
    "            comp_subset = comp_list[:n]\n",
    "    elif c == 2:\n",
    "        comp_subset = get_redownload_list(year)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    print(f\"Initiating search of Annual reports for the {year}......\\n\")\n",
    "    dic = {}\n",
    "    for x in comp_subset:\n",
    "        comp = x.strip()\n",
    "        #if the pdf of a year exist\n",
    "        if os.path.exists(f\"pdf/{year}\") == False:\n",
    "            os.mkdir(f\"pdf/{year}\")\n",
    "        if c == 1:\n",
    "            if os.path.exists(f\"pdf/{year}/{comp}\"):\n",
    "                if os.listdir(f\"pdf/{year}/{comp}\") != []:\n",
    "                    print(f\"{comp} already downloaded! Skipping search!\")\n",
    "                    continue\n",
    "        \n",
    "#       query = f\"{comp} annual report site:\\\"https://www.bseindia.com\\\" filetype:pdf intext:\\\"{year} {year+1}\\\" \" \n",
    "#         query = f\"{comp} bse annual report {year}-{year+1} filetype:pdf intext:\\\"{comp}\\\" \"\n",
    "        query = f\"{comp} bse annual report {year} filetype:pdf intext:\\\"{comp}\\\" \"\n",
    "\n",
    "#             query2 = f\"{comp} annual report 2019-20 intext:\\\"Do you have a policy\\\" filetype:pdf\"\n",
    "        print(f\"\\nLinks for {comp} --------------------------------------------\\n\")\n",
    "        links = []\n",
    "        link = \"\"\n",
    "        title = \"\"\n",
    "        desc = \"\"\n",
    "        result = google_results(query,1)\n",
    "        for r in result:\n",
    "            title = r[\"title\"]\n",
    "            desc = r[\"desc\"]\n",
    "            link = r[\"link\"]\n",
    "            print(f\"\\nTitle : {color.BOLD}{title}{color.END}\")\n",
    "            print(f\"Description : {desc}\")\n",
    "            print(f\"link :{link}\")\n",
    "#             if f\"{year-1}\" in desc or f\"{year-1}\" in title:\n",
    "#                 print(\"SKIPPING.......\")\n",
    "#                 continue\n",
    "            links.append(link)\n",
    "#             break\n",
    "        dic[x] = links\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHello World !\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "print(color.BOLD + 'Hello World !' + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading PDF from the list of links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filesize(download_path):\n",
    "    file_size = os.path.getsize(f\"{download_path}\")\n",
    "    return file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_links(file_name):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(y):\n",
    "    #check for pdf extension in link if not then add\n",
    "    if re.findall(\"pdf\", y) == []:\n",
    "        file_name = os.path.split(y)[1] + \".pdf\"\n",
    "    else:\n",
    "        file_name = os.path.split(y)[1]\n",
    "    ##check for pdf in filename\n",
    "    if re.findall(\"pdf\",file_name) == []:\n",
    "        y = y.replace(file_name,\"\")\n",
    "        file_name = os.path.split(y[:-1])[1]\n",
    "    \n",
    "    i = file_name.find(\"pdf\")\n",
    "    if i > 0:\n",
    "        file_name =  file_name[:i+3]\n",
    "        \n",
    "    ##check for special characters\n",
    "    pattern= \"'[@!#$^&*%<>?/\\\\|}{~:]'\\\"=\"\n",
    "    \n",
    "    for x in pattern:\n",
    "        n = file_name.replace(x,\"\")\n",
    "        file_name = n\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##download directly\n",
    "def download_pdf_direct(y,file_name,year,company_name):\n",
    "    response = requests.get(y)\n",
    "    pdf = open(f\"pdf/{year}/{company_name}/{file_name}\", 'wb')\n",
    "    pdf.write(response.content)\n",
    "    pdf.close()\n",
    "    print(f\"\\t{file_name} downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##download at each folder\n",
    "def download_all_pdf(dic,year = None):\n",
    "    if year == None:\n",
    "        year = int(input(\"Enter year : \"))\n",
    "    error_files = []\n",
    "    for x in dic:\n",
    "        company_name = x.strip()\n",
    "        link_of_pdfs = dic[x]\n",
    "        path = \"pdf\"\n",
    "        download_path = f\"{path}/{year}/{company_name}\"\n",
    "        #go to pdf and create folder\n",
    "        if os.path.exists(f\"{path}/{year}\") == False:\n",
    "            os.mkdir(f\"{path}/{year}\")\n",
    "        if os.path.exists(download_path) == False:\n",
    "            os.mkdir(download_path)\n",
    "        f_size = get_filesize(f\"{download_path}\")\n",
    "        if os.listdir(download_path) == [] or f_size < 10000:\n",
    "            print(f\"Downloading report for {company_name}\")\n",
    "            for y in link_of_pdfs:\n",
    "                #gets the pdf name from the link\n",
    "                file_name = get_filename(y)\n",
    "                try:\n",
    "#                     print(f\"{y}\\n{file_name}\\n{company_name}\")\n",
    "                    download_pdf_direct(y,file_name,year,company_name)\n",
    "                except:\n",
    "                    print(f\"!!!!!------------Some error occured while downloading {file_name}\")\n",
    "                    error_files.append(company_name)\n",
    "            print(f\"All {company_name} report downloaded\")\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    print(\"Download complete!\")\n",
    "    \n",
    "    \n",
    "    if error_files != []:\n",
    "        print(\"List of company not downloaded\")\n",
    "        with open(f\"pdf/comp_{year}.txt\",\"w\") as f:\n",
    "            for x in error_files:\n",
    "                print(f\"\\t{x}\")\n",
    "                f.write(x+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start search and download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_it():\n",
    "    y = int(input(\"Enter year :\"))\n",
    "    choice = \"\"\n",
    "    if os.path.exists(f\"pdf/{y}\"):\n",
    "        check_files(y)\n",
    "        choice = input(\"Do you want to download? y or n :\")\n",
    "        \n",
    "    if choice == \"y\":\n",
    "        comp_dict = search_and_get_pdf(None,y,2)\n",
    "    else:\n",
    "        comp_dict = search_and_get_pdf(None,y,1)\n",
    "    \n",
    "    download_all_pdf(comp_dict,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate downloaded files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_files(year):\n",
    "    with open(f\"pdf/broken_files_{year}.txt\",\"w\") as f:\n",
    "        for i in os.listdir(f\"pdf/{year}/\"):\n",
    "            path = f\"pdf/{year}/{i}/\"\n",
    "            file = os.listdir(path)\n",
    "            if file == []:\n",
    "                continue\n",
    "            file_path = path+file[0]\n",
    "            file_size = os.path.getsize(file_path)\n",
    "    #         print(f\"{i} File Size is :{file_size} bytes\")\n",
    "            if file_size < 10000:\n",
    "                f.write(f\"{i}\\n\")\n",
    "                print(f\"{i} file size is too small {file_size} bytes\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank of India file size is too small 345 bytes\n",
      "\n",
      "Canara Bank file size is too small 345 bytes\n",
      "\n",
      "Coal India file size is too small 345 bytes\n",
      "\n",
      "GAIL (India) file size is too small 6 bytes\n",
      "\n",
      "General Insurance Corporation of India file size is too small 345 bytes\n",
      "\n",
      "Hindustan Unilever file size is too small 0 bytes\n",
      "\n",
      "Jindal Steel & Power file size is too small 345 bytes\n",
      "\n",
      "Larsen & Toubro file size is too small 0 bytes\n",
      "\n",
      "Mahindra & Mahindra file size is too small 345 bytes\n",
      "\n",
      "NTPC file size is too small 345 bytes\n",
      "\n",
      "Oil & Natural Gas Corporation file size is too small 43 bytes\n",
      "\n",
      "Power Grid Corporation of India file size is too small 0 bytes\n",
      "\n",
      "Reliance Industries file size is too small 345 bytes\n",
      "\n",
      "State Bank of India file size is too small 345 bytes\n",
      "\n",
      "Steel Authority of India file size is too small 345 bytes\n",
      "\n",
      "Tech Mahindra file size is too small 0 bytes\n",
      "\n",
      "UltraTech Cement file size is too small 345 bytes\n",
      "\n",
      "Union Bank of India file size is too small 345 bytes\n",
      "\n",
      "Vedanta file size is too small 345 bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_files(2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get redownload list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redownload_list(year):\n",
    "    path = f\"pdf/broken_files_{year}.txt\"\n",
    "    with open(path, \"r\") as f:\n",
    "        r_list = f.readlines()\n",
    "    return r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter year : 2020\n",
      "How many companies would you like to search? :  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating search of Annual reports for the 2020......\n",
      "\n",
      "\n",
      "Links for Reliance Industries --------------------------------------------\n",
      "\n",
      "\n",
      "Title : \u001b[1m[PDF] Annual Report - BSE\u001b[0m\n",
      "Description : 31-Mar-2020 · Reliance Industries Limited. Integrated Annual Report 2019-20. Naye India Ka Naya Josh. RELIANCE RETAIL. Reliance Retail continues to grow ...\n",
      "link :https://www.bseindia.com/bseplus/AnnualReport/500325/5003250320.pdf\n",
      "\n",
      "Links for Indian Oil Corporation --------------------------------------------\n",
      "\n",
      "\n",
      "Title : \u001b[1m[PDF] Integrated Annual Report 2019-20 - Iocl.com\u001b[0m\n",
      "Description : 21-Aug-2020 · Indian Oil Corporation Limited. 3rd Integrated Annual Report. 2. 3. ABOUT THE REPORT. Reporting Approach. With extensive petroleum refining, ...\n",
      "link :https://iocl.com/download/IndianOil-Annual-Report-2019-20.pdf\n",
      "\n",
      "Links for Oil & Natural Gas Corporation --------------------------------------------\n",
      "\n",
      "\n",
      "Title : \u001b[1m[PDF] Annual Report 2018-19 - ONGC\u001b[0m\n",
      "Description : 25-Jul-2019 · dedicated energy soldiers of Oil & Natural Gas Corporation. Ltd (ONGC), I now present to you the Company's Annual. Report for the financial ...\n",
      "link :https://www.ongcindia.com/wps/wcm/connect/a424064f-1ad7-4b99-b8ed-a00874496b3c/annualreport201819.pdf%3FMOD%3DAJPERES%26CONVERT_TO%3Durl%26CACHEID%3DROOTWORKSPACE-a424064f-1ad7-4b99-b8ed-a00874496b3c-mNwhsly\n",
      "\n",
      "Links for State Bank of India --------------------------------------------\n",
      "\n",
      "\n",
      "Title : \u001b[1m[PDF] Annual Report - SBI\u001b[0m\n",
      "Description : 23-Jun-2020 · India made up to the 31st day of March 2020, the report of the Central Board on the working and activities of the State Bank of India for ...\n",
      "link :https://www.sbi.co.in/documents/17826/35696/23062020_SBI%2BAR%2B2019-20%2B%2528Time%2B16_3b11%2529.pdf/a358b5ec-1d32-a093-d9ac-13071fda9ff6%3Ft%3D1592911831224\n",
      "\n",
      "Links for Bharat Petroleum Corporation --------------------------------------------\n",
      "\n",
      "\n",
      "Title : \u001b[1m[PDF] Sec.3.4.1 (L) The Secretary, BSE Ltd., Phiroze ... - Bharat Petroleum\u001b[0m\n",
      "Description : We would like to inform you that the 67111 Annual General Meeting of the Company was held on. Monday, 28111 September, 2020 at 11.00 a.m. through Video- ...\n",
      "link :https://www.bharatpetroleum.com/images/files/stexchagmproceedings2020.pdf\n",
      "Downloading report for Reliance Industries\n",
      "\t5003250320.pdf downloaded\n",
      "All Reliance Industries report downloaded\n",
      "Downloading report for Indian Oil Corporation\n",
      "\tIndianOil-Annual-Report-2019-20.pdf downloaded\n",
      "All Indian Oil Corporation report downloaded\n",
      "Downloading report for Oil & Natural Gas Corporation\n",
      "\tannualreport201819.pdf downloaded\n",
      "All Oil & Natural Gas Corporation report downloaded\n",
      "Downloading report for State Bank of India\n",
      "\t23062020_SBI2BAR2B2019-202B2528Time2B16_3b112529.pdf downloaded\n",
      "All State Bank of India report downloaded\n",
      "Downloading report for Bharat Petroleum Corporation\n",
      "\tstexchagmproceedings2020.pdf downloaded\n",
      "All Bharat Petroleum Corporation report downloaded\n",
      "----------------------------------------------------------------------------------\n",
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "start_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oil & Natural Gas Corporation file size is too small 43 bytes\n",
      "\n",
      "Reliance Industries file size is too small 345 bytes\n",
      "\n",
      "State Bank of India file size is too small 245 bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_files(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems\n",
    "    1. Fix the download pdf from link function\n",
    "    2. Turn it int OOP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from googlesearch import search\n",
    "import webbrowser\n",
    "import re\n",
    "import urllib.request\n",
    "import requests\n",
    "import bs4\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fake_useragent import UserAgent\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_comp_list(path = \"Top 500 companies.txt\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        comp_list = f.readlines()\n",
    "    return comp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching PDF with google scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_results(keyword, n_results=10):\n",
    "    query = keyword\n",
    "    query = urllib.parse.quote_plus(query) # Format into URL encoding\n",
    "    number_result = n_results\n",
    "    ua = UserAgent()\n",
    "    google_url = f\"https://www.google.com/search?q= {query} &num= + {number_result}\"\n",
    "    response = requests.get(google_url, {\"User-Agent\": ua.random})\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    links = get_links(soup)\n",
    "    titles = get_title_list(soup)\n",
    "    desc_list = get_desc(soup)\n",
    "    lst = []\n",
    "    for (l,t,d) in zip(links,titles,desc_list):\n",
    "        lst.append({\"title\" : t, \"link\" : l, \"desc\" : d})\n",
    "    return lst[:number_result]\n",
    "\n",
    "def get_links(soup):\n",
    "    result = soup.find_all('div', attrs = {'class': 'ZINbbc'})\n",
    "    pattern = '\\/url\\?q\\=(.*)\\&sa'\n",
    "    results = []\n",
    "    for i in result:\n",
    "        if \"url\" in str(i):\n",
    "            text = str(i.find('a', href = True)['href'])\n",
    "            results.append(re.search(pattern,text))\n",
    "    #group(1) returns the text of the match object\n",
    "    links=[i.group(1) for i in results if i != None]\n",
    "    return links\n",
    "\n",
    "def get_title_list(soup):\n",
    "    result = soup.find_all('h3', attrs = {'class': 'zBAuLc'})\n",
    "    titles = [i.text for i in result]\n",
    "    return titles\n",
    "\n",
    "def get_desc(soup):\n",
    "    result = soup.findAll(True, {'class':\"kCrYT\"})\n",
    "    desc_list = []\n",
    "    for i,r in enumerate(result):\n",
    "        if i % 2 != 0:\n",
    "            desc_list.append(r.text)     \n",
    "    return desc_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_get_pdf(n = None,year = None, c=None):\n",
    "    if c == None:\n",
    "        c = int(input(\"Enter\\n1. Normal Downlaod\\n2. Redownload \\n\"))\n",
    "    if c == 1:\n",
    "        comp_list = get_comp_list()\n",
    "        if year == None:\n",
    "            year = int(input(\"Enter year : \"))\n",
    "        if n == None:\n",
    "            n = int(input(\"How many companies would you like to search? : \"))\n",
    "            comp_subset = comp_list[:n]\n",
    "    elif c == 2:\n",
    "        comp_subset = get_redownload_list(year)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    print(f\"Initiating search of Annual reports for the {year}......\\n\")\n",
    "    dic = {}\n",
    "    for x in comp_subset:\n",
    "        comp = x.strip()\n",
    "        #if the pdf of a year exist\n",
    "        if os.path.exists(f\"pdf/{year}\") == False:\n",
    "            os.mkdir(f\"pdf/{year}\")\n",
    "        if c == 1:\n",
    "            if os.path.exists(f\"pdf/{year}/{comp}\"):\n",
    "                if os.listdir(f\"pdf/{year}/{comp}\") != []:\n",
    "                    print(f\"{comp} already downloaded! Skipping search!\")\n",
    "                    continue\n",
    "        \n",
    "#       query = f\"{comp} annual report site:\\\"https://www.bseindia.com\\\" filetype:pdf intext:\\\"{year} {year+1}\\\" \" \n",
    "#         query = f\"{comp} bse annual report {year}-{year+1} filetype:pdf intext:\\\"{comp}\\\" \"\n",
    "        query = f\"{comp} bse annual report {year} filetype:pdf intext:\\\"{comp}\\\" \"\n",
    "\n",
    "#             query2 = f\"{comp} annual report 2019-20 intext:\\\"Do you have a policy\\\" filetype:pdf\"\n",
    "        print(f\"\\nLinks for {comp} --------------------------------------------\\n\")\n",
    "        links = []\n",
    "        link = \"\"\n",
    "        title = \"\"\n",
    "        desc = \"\"\n",
    "        result = google_results(query,1)\n",
    "        for r in result:\n",
    "            title = r[\"title\"]\n",
    "            desc = r[\"desc\"]\n",
    "            link = r[\"link\"]\n",
    "            print(f\"\\nTitle : {color.BOLD}{title}{color.END}\")\n",
    "            print(f\"Description : {desc}\")\n",
    "            print(f\"link :{link}\")\n",
    "#             if f\"{year-1}\" in desc or f\"{year-1}\" in title:\n",
    "#                 print(\"SKIPPING.......\")\n",
    "#                 continue\n",
    "            links.append(link)\n",
    "#             break\n",
    "        dic[x] = links\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHello World !\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "print(color.BOLD + 'Hello World !' + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading PDF from the list of links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filesize(download_path):\n",
    "    file_size = os.path.getsize(f\"{download_path}\")\n",
    "    return file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_links(file_name):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(y):\n",
    "    #check for pdf extension in link if not then add\n",
    "    if re.findall(\"pdf\", y) == []:\n",
    "        file_name = os.path.split(y)[1] + \".pdf\"\n",
    "    else:\n",
    "        file_name = os.path.split(y)[1]\n",
    "    ##check for pdf in filename\n",
    "    if re.findall(\"pdf\",file_name) == []:\n",
    "        y = y.replace(file_name,\"\")\n",
    "        file_name = os.path.split(y[:-1])[1]\n",
    "    \n",
    "    i = file_name.find(\"pdf\")\n",
    "    if i > 0:\n",
    "        file_name =  file_name[:i+3]\n",
    "        \n",
    "    ##check for special characters\n",
    "    pattern= \"'[@!#$^&*%<>?/\\\\|}{~:]'\\\"=\"\n",
    "    \n",
    "    for x in pattern:\n",
    "        n = file_name.replace(x,\"\")\n",
    "        file_name = n\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##download directly\n",
    "def download_pdf_direct(y,file_name,year,company_name):\n",
    "    response = requests.get(y)\n",
    "    pdf = open(f\"pdf/{year}/{company_name}/{file_name}\", 'wb')\n",
    "    pdf.write(response.content)\n",
    "    pdf.close()\n",
    "    print(f\"\\t{file_name} downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##download at each folder\n",
    "def download_all_pdf(dic,year = None):\n",
    "    if year == None:\n",
    "        year = int(input(\"Enter year : \"))\n",
    "    error_files = []\n",
    "    for x in dic:\n",
    "        company_name = x.strip()\n",
    "        link_of_pdfs = dic[x]\n",
    "        path = \"pdf\"\n",
    "        download_path = f\"{path}/{year}/{company_name}\"\n",
    "        #go to pdf and create folder\n",
    "        if os.path.exists(f\"{path}/{year}\") == False:\n",
    "            os.mkdir(f\"{path}/{year}\")\n",
    "        if os.path.exists(download_path) == False:\n",
    "            os.mkdir(download_path)\n",
    "        f_size = get_filesize(f\"{download_path}\")\n",
    "        if os.listdir(download_path) == [] or f_size < 10000:\n",
    "            print(f\"Downloading report for {company_name}\")\n",
    "            for y in link_of_pdfs:\n",
    "                #gets the pdf name from the link\n",
    "                file_name = get_filename(y)\n",
    "                try:\n",
    "#                     print(f\"{y}\\n{file_name}\\n{company_name}\")\n",
    "                    download_pdf_direct(y,file_name,year,company_name)\n",
    "                except:\n",
    "                    print(f\"!!!!!------------Some error occured while downloading {file_name}\")\n",
    "                    error_files.append(company_name)\n",
    "            print(f\"All {company_name} report downloaded\")\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    print(\"Download complete!\")\n",
    "    \n",
    "    \n",
    "    if error_files != []:\n",
    "        print(\"List of company not downloaded\")\n",
    "        with open(f\"pdf/comp_{year}.txt\",\"w\") as f:\n",
    "            for x in error_files:\n",
    "                print(f\"\\t{x}\")\n",
    "                f.write(x+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start search and download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_it():\n",
    "    y = int(input(\"Enter year :\"))\n",
    "    check_files(y)\n",
    "    choice = input(\"Do you want to download? y or n :\")\n",
    "    if choice == \"y\":\n",
    "        comp_dict = search_and_get_pdf(None,y,2)\n",
    "    else:\n",
    "        comp_dict = search_and_get_pdf(None,y)\n",
    "    download_all_pdf(comp_dict,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate downloaded files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_files(year):\n",
    "    with open(f\"pdf/broken_files_{year}.txt\",\"w\") as f:\n",
    "        for i in os.listdir(f\"pdf/{year}/\"):\n",
    "            path = f\"pdf/{year}/{i}/\"\n",
    "            file = os.listdir(path)\n",
    "            if file == []:\n",
    "                continue\n",
    "            file_path = path+file[0]\n",
    "            file_size = os.path.getsize(file_path)\n",
    "    #         print(f\"{i} File Size is :{file_size} bytes\")\n",
    "            if file_size < 10000:\n",
    "                f.write(f\"{i}\\n\")\n",
    "                print(f\"{i} file size is too small {file_size} bytes\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get redownload list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redownload_list(year):\n",
    "    path = f\"pdf/broken_files_{year}.txt\"\n",
    "    with open(path, \"r\") as f:\n",
    "        r_list = f.readlines()\n",
    "    return r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_it()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

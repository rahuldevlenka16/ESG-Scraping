{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems\n",
    "    1. Fix the download pdf from link function\n",
    "        1.1 file stuck at download\n",
    "        1.2 broken file download\n",
    "    2. Turn it int OOP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from googlesearch import search\n",
    "import webbrowser\n",
    "import re\n",
    "import urllib.request\n",
    "import requests\n",
    "import bs4\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fake_useragent import UserAgent\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_comp_list(path = \"Top 500 companies.txt\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        comp_list = f.readlines()\n",
    "    return comp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching PDF with no block(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_results(keyword, n_results=10):\n",
    "    query = keyword\n",
    "    query = urllib.parse.quote_plus(query) # Format into URL encoding\n",
    "    number_result = n_results\n",
    "    ua = UserAgent()\n",
    "    google_url = f\"https://www.google.com/search?q= {query} &num= + {number_result}\"\n",
    "    response = requests.get(google_url, {\"User-Agent\": ua.random})\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    links = get_links(soup)\n",
    "    titles = get_title_list(soup)\n",
    "    desc_list = get_desc(soup)\n",
    "    lst = []\n",
    "    for (l,t,d) in zip(links,titles,desc_list):\n",
    "        lst.append({\"title\" : t, \"link\" : l, \"desc\" : d})\n",
    "    return lst[:number_result]\n",
    "\n",
    "def get_links(soup):\n",
    "    result = soup.find_all('div', attrs = {'class': 'ZINbbc'})\n",
    "    pattern = '\\/url\\?q\\=(.*)\\&sa'\n",
    "    results = []\n",
    "    for i in result:\n",
    "        if \"url\" in str(i):\n",
    "            text = str(i.find('a', href = True)['href'])\n",
    "            results.append(re.search(pattern,text))\n",
    "    #group(1) returns the text of the match object\n",
    "    links=[i.group(1) for i in results if i != None]\n",
    "    return links\n",
    "\n",
    "def get_title_list(soup):\n",
    "    result = soup.find_all('h3', attrs = {'class': 'zBAuLc'})\n",
    "    titles = [i.text for i in result]\n",
    "    return titles\n",
    "\n",
    "def get_desc(soup):\n",
    "    result = soup.findAll(True, {'class':\"kCrYT\"})\n",
    "    desc_list = []\n",
    "    for i,r in enumerate(result):\n",
    "        if i % 2 != 0:\n",
    "            desc_list.append(r.text)     \n",
    "    return desc_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_get_pdf(n = None,year = None, c=None):\n",
    "    if c == None:\n",
    "        c = int(input(\"Enter\\n1. Normal Downlaod\\n2. Redownload \\n\"))\n",
    "    if c == 1:\n",
    "        comp_list = get_comp_list()\n",
    "        if year == None:\n",
    "            year = int(input(\"Enter year : \"))\n",
    "        if n == None:\n",
    "            n = int(input(\"\\nHow many companies would you like to search? : \"))\n",
    "            comp_subset = comp_list[:n]\n",
    "    elif c == 2:\n",
    "        comp_subset = get_redownload_list(year)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nInitiating search of Annual reports for the {year}......\\n\")\n",
    "    time.sleep(2)\n",
    "    dic = {}\n",
    "    for x in comp_subset:\n",
    "        comp = x.strip()\n",
    "        #if the pdf of a year exist\n",
    "        if os.path.exists(f\"pdf/{year}\") == False:\n",
    "            os.mkdir(f\"pdf/{year}\")\n",
    "        if c == 1:\n",
    "            if os.path.exists(f\"pdf/{year}/{comp}\"):\n",
    "                if os.listdir(f\"pdf/{year}/{comp}\") != []:\n",
    "                    print(f\"{comp} already downloaded! Skipping search!\")\n",
    "                    continue\n",
    "        \n",
    "#       query = f\"{comp} annual report site:\\\"https://www.bseindia.com\\\" filetype:pdf intext:\\\"{year} {year+1}\\\" \" \n",
    "#         query = f\"{comp} bse annual report {year}-{year+1} filetype:pdf intext:\\\"{comp}\\\" \"\n",
    "        query = f\"{comp} bse annual report {year} filetype:pdf intext:\\\"{comp}\\\" \"\n",
    "\n",
    "#             query2 = f\"{comp} annual report 2019-20 intext:\\\"Do you have a policy\\\" filetype:pdf\"\n",
    "        print(f\"\\nLinks for {comp} --------------------------------------------\\n\")\n",
    "        links = []\n",
    "        link = \"\"\n",
    "        title = \"\"\n",
    "        desc = \"\"\n",
    "        result = google_results(query,1)\n",
    "        for r in result:\n",
    "            title = r[\"title\"]\n",
    "            desc = r[\"desc\"]\n",
    "            link = r[\"link\"]\n",
    "            print(f\"\\nTitle : {color.BOLD}{title}{color.END}\")\n",
    "            print(f\"Description : {desc}\")\n",
    "            print(f\"link :{link}\")\n",
    "#             if f\"{year-1}\" in desc or f\"{year-1}\" in title:\n",
    "#                 print(\"SKIPPING.......\")\n",
    "#                 continue\n",
    "            links.append(link)\n",
    "#             break\n",
    "        dic[x] = links\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHello World !\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "print(color.BOLD + 'Hello World !' + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading PDF from the list of links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filesize(download_path):\n",
    "    file_size = os.path.getsize(f\"{download_path}\")\n",
    "    return file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_links(file_name):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(y):\n",
    "    #check for pdf extension in link if not then add\n",
    "    if re.findall(\"pdf\", y) == []:\n",
    "        file_name = os.path.split(y)[1] + \".pdf\"\n",
    "    else:\n",
    "        file_name = os.path.split(y)[1]\n",
    "    ##check for pdf in filename\n",
    "    if re.findall(\"pdf\",file_name) == []:\n",
    "        y = y.replace(file_name,\"\")\n",
    "        file_name = os.path.split(y[:-1])[1]\n",
    "    \n",
    "    i = file_name.find(\"pdf\")\n",
    "    if i > 0:\n",
    "        file_name =  file_name[:i+3]\n",
    "        \n",
    "    ##check for special characters\n",
    "    pattern= \"'[@!#$^&*%<>?/\\\\|}{~:]'\\\"=\"\n",
    "    \n",
    "    for x in pattern:\n",
    "        n = file_name.replace(x,\"\")\n",
    "        file_name = n\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##download directly\n",
    "def download_pdf_direct(link,file_name,year,company_name):\n",
    "    path = f\"pdf/{year}/{company_name}/{file_name}\"\n",
    "    ua = UserAgent()\n",
    "    try:\n",
    "        response = requests.get(link, {\"User-Agent\": ua.random}, timeout = 180)\n",
    "        save_file(response,file_name,path)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(response,filename,download_path):\n",
    "#     download_path = \"temp/test_file2.pdf\"\n",
    "    with open(f\"{download_path}\", 'wb') as pdf:\n",
    "        pdf.write(response.content)\n",
    "    file_size = os.path.getsize(f\"{download_path}\")\n",
    "    size = round(file_size/(1024),3)\n",
    "    print(f\"\\tdownloaded filesize : {size}KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##download at each folder\n",
    "def download_all_pdf(dic,year = None):\n",
    "    if year == None:\n",
    "        year = int(input(\"Enter year : \"))\n",
    "    error_files = []\n",
    "    stuck_files = []\n",
    "    for x in dic:\n",
    "        company_name = x.strip()\n",
    "        link_of_pdfs = dic[x]\n",
    "        path = \"pdf\"\n",
    "        download_path = f\"{path}/{year}/{company_name}\"\n",
    "        #go to pdf and create folder\n",
    "        if os.path.exists(f\"{path}/{year}\") == False:\n",
    "            os.mkdir(f\"{path}/{year}\")\n",
    "        if os.path.exists(download_path) == False:\n",
    "            os.mkdir(download_path)\n",
    "        f_size = get_filesize(f\"{download_path}\")\n",
    "        if os.listdir(download_path) == [] or f_size < 10000:\n",
    "            print(f\"\\nDownloading report for {company_name}\")\n",
    "            check = \"\"\n",
    "            for y in link_of_pdfs:\n",
    "                #gets the pdf name from the link\n",
    "                file_name = get_filename(y)\n",
    "                try:\n",
    "#                     print(f\"{y}\\n{file_name}\\n{company_name}\")\n",
    "                    check = download_pdf_direct(y,file_name,year,company_name)\n",
    "                except:\n",
    "                    print(f\"!!!!!------------Some error occured while downloading {file_name}, skipping to next link.\")\n",
    "                    error_files.append(company_name)\n",
    "            if check:\n",
    "                print(f\"\\t{company_name} report downloaded\")\n",
    "            else:\n",
    "                print(\"!!!!------File is taking too long to download, skipping to next link\")\n",
    "                stuck_files.append(company_name)\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "    print(\"All download complete!\")\n",
    "    \n",
    "    \n",
    "    if error_files != []:\n",
    "        print(\"List of company not downloaded\")\n",
    "        with open(f\"pdf/logs/failed_files_{year}.txt\",\"w\") as f:\n",
    "            for x in error_files:\n",
    "                print(f\"\\t{x}\")\n",
    "                f.write(f\"{x}\\n\")\n",
    "                \n",
    "    if stuck_files!= []:\n",
    "        print(\"List of company skipped as it took too long to download \")\n",
    "        with open(f\"pdf/logs/stuck_files{year}.txt\",\"w\") as f:\n",
    "            for x in stuck_files:\n",
    "                print(f\"\\t{x}\")\n",
    "                f.write(f\"{x}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start search and download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_it():\n",
    "    y = int(input(\"Enter year :\"))\n",
    "    choice = \"\"\n",
    "    if os.path.exists(f\"pdf/{y}\"):\n",
    "        print(\"\\nChecking previous downloads for broken files......\\n\")\n",
    "        time.sleep(2)\n",
    "        check_files(y)\n",
    "        choice = input(\"Do you want to re-download these files? y or n :\")\n",
    "\n",
    "    if choice == \"y\":\n",
    "        comp_dict = search_and_get_pdf(None,y,2)\n",
    "    else:\n",
    "        comp_dict = search_and_get_pdf(None,y,1)\n",
    "\n",
    "    download_all_pdf(comp_dict,y)\n",
    "    print(\"\\nReckecking for broken downloads.....\\n\")\n",
    "    time.sleep(2)\n",
    "    check_files(y)\n",
    "    print(color.GREEN + \"Everyting is completed successfully!\" + color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate downloaded files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_files(year):\n",
    "    f = open(f\"pdf/logs/broken_files_{year}.txt\",\"w\")\n",
    "    f2 = open(f\"pdf/logs/success_files_{year}.txt\",\"w\")\n",
    "    for i in os.listdir(f\"pdf/{year}/\"):\n",
    "        path = f\"pdf/{year}/{i}/\"\n",
    "        file = os.listdir(path)\n",
    "        if file == []:\n",
    "            continue\n",
    "        file_path = path+file[0]\n",
    "        file_size = os.path.getsize(file_path)\n",
    "#         print(f\"{i} File Size is :{file_size} bytes\")\n",
    "        #add to broken download list\n",
    "        if file_size < 10000:\n",
    "            f.write(f\"{i}\\n\")\n",
    "            print(f\"{i} file size is too small {file_size} bytes\\n\")\n",
    "        #add to success download list\n",
    "        else:\n",
    "            f2.write(f\"{i}\\n\")\n",
    "\n",
    "    f.close()\n",
    "    f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get redownload list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redownload_list(year):\n",
    "    path = f\"pdf/broken_files_{year}.txt\"\n",
    "    with open(path, \"r\") as f:\n",
    "        r_list = f.readlines()\n",
    "    return r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter year : 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking previous downloads for broken files......\n",
      "\n",
      "Bank of India file size is too small 0 bytes\n",
      "\n",
      "Canara Bank file size is too small 345 bytes\n",
      "\n",
      "Coal India file size is too small 345 bytes\n",
      "\n",
      "GAIL (India) file size is too small 6 bytes\n",
      "\n",
      "General Insurance Corporation of India file size is too small 345 bytes\n",
      "\n",
      "Hindustan Unilever file size is too small 0 bytes\n",
      "\n",
      "InterGlobe Aviation file size is too small 345 bytes\n",
      "\n",
      "Jindal Steel & Power file size is too small 345 bytes\n",
      "\n",
      "Larsen & Toubro file size is too small 0 bytes\n",
      "\n",
      "Mahindra & Mahindra file size is too small 345 bytes\n",
      "\n",
      "NTPC file size is too small 345 bytes\n",
      "\n",
      "Oil & Natural Gas Corporation file size is too small 43 bytes\n",
      "\n",
      "Power Grid Corporation of India file size is too small 0 bytes\n",
      "\n",
      "Reliance Industries file size is too small 345 bytes\n",
      "\n",
      "State Bank of India file size is too small 345 bytes\n",
      "\n",
      "Steel Authority of India file size is too small 345 bytes\n",
      "\n",
      "Tech Mahindra file size is too small 0 bytes\n",
      "\n",
      "UltraTech Cement file size is too small 345 bytes\n",
      "\n",
      "Union Bank of India file size is too small 345 bytes\n",
      "\n",
      "Vedanta file size is too small 345 bytes\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to re-download these files? y or n : n\n",
      "\n",
      "How many companies would you like to search? :  50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initiating search of Annual reports for the 2018......\n",
      "\n",
      "Reliance Industries already downloaded! Skipping search!\n",
      "Indian Oil Corporation already downloaded! Skipping search!\n",
      "Oil & Natural Gas Corporation already downloaded! Skipping search!\n",
      "State Bank of India already downloaded! Skipping search!\n",
      "Bharat Petroleum Corporation already downloaded! Skipping search!\n",
      "Tata Motors already downloaded! Skipping search!\n",
      "Rajesh Exports already downloaded! Skipping search!\n",
      "Tata Consultancy Services already downloaded! Skipping search!\n",
      "ICICI Bank already downloaded! Skipping search!\n",
      "Larsen & Toubro already downloaded! Skipping search!\n",
      "HDFC Bank already downloaded! Skipping search!\n",
      "Tata Steel already downloaded! Skipping search!\n",
      "Hindalco Industries already downloaded! Skipping search!\n",
      "NTPC already downloaded! Skipping search!\n",
      "HDFC already downloaded! Skipping search!\n",
      "Coal India already downloaded! Skipping search!\n",
      "Mahindra & Mahindra already downloaded! Skipping search!\n",
      "Infosys already downloaded! Skipping search!\n",
      "Bank of Baroda already downloaded! Skipping search!\n",
      "Bharti Airtel already downloaded! Skipping search!\n",
      "Nayara Energy already downloaded! Skipping search!\n",
      "Vedanta already downloaded! Skipping search!\n",
      "Axis Bank already downloaded! Skipping search!\n",
      "Grasim Industries already downloaded! Skipping search!\n",
      "Maruti Suzuki India already downloaded! Skipping search!\n",
      "GAIL (India) already downloaded! Skipping search!\n",
      "JSW Steel already downloaded! Skipping search!\n",
      "HCL Technologies already downloaded! Skipping search!\n",
      "Steel Authority of India already downloaded! Skipping search!\n",
      "Punjab National Bank already downloaded! Skipping search!\n",
      "Motherson Sumi Systems already downloaded! Skipping search!\n",
      "Wipro already downloaded! Skipping search!\n",
      "Power Finance Corporation already downloaded! Skipping search!\n",
      "Canara Bank already downloaded! Skipping search!\n",
      "Bajaj Finserv already downloaded! Skipping search!\n",
      "ITC already downloaded! Skipping search!\n",
      "General Insurance Corporation of India already downloaded! Skipping search!\n",
      "Kotak Mahindra Bank already downloaded! Skipping search!\n",
      "Bank of India already downloaded! Skipping search!\n",
      "Vodafone Idea already downloaded! Skipping search!\n",
      "Jindal Steel & Power already downloaded! Skipping search!\n",
      "Union Bank of India already downloaded! Skipping search!\n",
      "UltraTech Cement already downloaded! Skipping search!\n",
      "Power Grid Corporation of India already downloaded! Skipping search!\n",
      "Hindustan Unilever already downloaded! Skipping search!\n",
      "Tech Mahindra already downloaded! Skipping search!\n",
      "\n",
      "Links for Yes Bank --------------------------------------------\n",
      "\n",
      "\n",
      "Title : \u001b[1m[PDF] Annual Report 2018-19 - Yes Bank\u001b[0m\n",
      "Description : 15-Mar-2018 Â· Report on Corporate Governance. 131. 68-183. STATUTORY REPORTS. YES BANK at a glance. 2. Banking Re-Imagined. 3. Financial Highlights.\n",
      "link :https://www.yesbank.in/pdf/annualreport_2018_19_pdf\n",
      "InterGlobe Aviation already downloaded! Skipping search!\n",
      "UPL already downloaded! Skipping search!\n",
      "IndusInd Bank already downloaded! Skipping search!\n",
      "\n",
      "Downloading report for Yes Bank\n",
      "!!!!------File is taking too long to download, skipping to next link\n",
      "----------------------------------------------------------------------------------\n",
      "All download complete!\n",
      "\tYes Bank\n",
      "\n",
      "Reckecking for broken downloads.....\n",
      "\n",
      "Bank of India file size is too small 0 bytes\n",
      "\n",
      "Canara Bank file size is too small 345 bytes\n",
      "\n",
      "Coal India file size is too small 345 bytes\n",
      "\n",
      "GAIL (India) file size is too small 6 bytes\n",
      "\n",
      "General Insurance Corporation of India file size is too small 345 bytes\n",
      "\n",
      "Hindustan Unilever file size is too small 0 bytes\n",
      "\n",
      "InterGlobe Aviation file size is too small 345 bytes\n",
      "\n",
      "Jindal Steel & Power file size is too small 345 bytes\n",
      "\n",
      "Larsen & Toubro file size is too small 0 bytes\n",
      "\n",
      "Mahindra & Mahindra file size is too small 345 bytes\n",
      "\n",
      "NTPC file size is too small 345 bytes\n",
      "\n",
      "Oil & Natural Gas Corporation file size is too small 43 bytes\n",
      "\n",
      "Power Grid Corporation of India file size is too small 0 bytes\n",
      "\n",
      "Reliance Industries file size is too small 345 bytes\n",
      "\n",
      "State Bank of India file size is too small 345 bytes\n",
      "\n",
      "Steel Authority of India file size is too small 345 bytes\n",
      "\n",
      "Tech Mahindra file size is too small 0 bytes\n",
      "\n",
      "UltraTech Cement file size is too small 345 bytes\n",
      "\n",
      "Union Bank of India file size is too small 345 bytes\n",
      "\n",
      "Vedanta file size is too small 345 bytes\n",
      "\n",
      "\u001b[92mEveryting is completed successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_it()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
